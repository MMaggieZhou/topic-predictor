Please follow instructions of below files contained in Assignment5-Mengqi_Zhou folder, before reading and running code.

2. "initial_data" folder: this folder includes necessary data for classification based on association rules in this assignment. 
	2.1 feature_vectors.csv: this file records feature vectors for 8391 document with 4953 features.
	2.2 binary_class_labels.csv: this file recors label vectors for 8391 document with 119 class labels, in binary format.
	2.3 training_article_numbers.csv: this file shows which documents are assigned as training document.
	2.4 test_article_numbers.csv: this file shows which documents are assigned as test document.
	2.5 cosine_8.csv: this file shows the document numbers that are assigned in each of the eight clusters.
	2.6 cosine_14.csv: this file shows the document numbers that are assigned in each of the fourteen clusters.
3. "rules" folder: this folder include association rules generated from algorithm1 and algorithm2
	3.1 "algorithm1"/combined_rules: this file include all association rules generated in algorithm1. First attribute is a class label as consequence, last two attributes are support and confidence, and the rest are features as condition.
	3.2 "algorithm2"/"8culsters":this folder include association rules generated within each clusters, the file is named by cluster number.
	3.2 "algorithm2"/"14clusters:"this folder include association rules generated within each clusters, the file is named by cluster number.
4. apriori: this folder is the free software that are borrowed from www.borgelt.net for association rule generation by apriori.
5. source_code: this folder include code written in python that are necessary for classification in this assignment.
	5.1 transformation.py: module containing method for transform binary vectors into transactions, do not run it directly.
	5.2 prune.py: module containing method for rule prunning, do not run it directly.
	5.3 leftover.py: module containing method for collecting transactions that not covered ay any rules, do not run it directly.
	5.4 merge_rule.py: module containing method for merging rules generated from different iterations. To run the code, (1) open the file, change oldsize into the size of training transactions; (2) change new_rule into the file address of new rules to merge; (3) change newsize into the size of transactions from which the new rules are generated; (4) change combined_rules into the file address you are going to store all combined rules; (5) change old_rule into the file address where the old rules are;(6) save and close the file. (7) in terminal, nativate into the folder there this code is, and type" merge_rule.py" and hit Enter to run the code.
	5.5 select_rules.py: module containing method for classification, do not run it directly.
	5.6 accuracy2.py: module containing method for calculating accuracy of classification, do not run it directly.
	5.7 "algorithm1"folder: contains code to use above methods for classification in algorithm1
		5.7.1 partition.py: containing code to partition the binary dataset into training dataset and test dataset, also in binary format. to run the code, (1) open the file, change tan into address of 2.4, change tran into address of 2.3, change allvector into address of 2.1, and change alllabel into address of 2.2, change folder into address of folder where you want to store the binary dataset for training and test data; (2) save, close the file; (3) in a terminal, nativate to the folder of this file and type "partition.py", then hit Enter to run the code.
		5.7.2 create_transaction.py: containing code to generate transactions for both test data and training data. To run the code, (1) open the file, change trvb, trlb, ttb, tevb , telb and tetb into address of files generated by running 5.7.1; (2) save, close the file; (3) in a terminal, nativate to the folder of this file and type "create_transaction.py", then hit Enter to run the code.
		5.7.3 ruleprun.py: containing code to prune rules so that all left rules are in legitimate formate. To run the code, (1) open the file, change prbase into address of file you want to store rules after pruning, change outputbase into address of file that contains rules generated by running "Apriori" software in section4; (2) save, close the file; (3) in a terminal, nativate to the folder of this file and type "ruleprun.py", then hit Enter to run the code.
		5.7.4 leftover_transactions.py: containing code to collect transactions that are not covered by any rules. To run the code, (1) open the file, change ltbase into address of file that you want to store left over transactions, change nfbase into address of file that you want to store transactions that don't have features (usually it will be empty, but just in case), change rbase into address of file that collect transactions to scan, change rulebase into address of file that collect rules generated by rbase in this iteration; (2) save, close the file; (3) in a terminal, nativate to the folder of this file and type "leftover_transactions.py", then hit Enter to run the code.
		5.7.5 select_rule.py: containing code for classification in algorithm1 based on association rules and transaction. To run the code, (1) open the file, change tlbase into the address of file that you want to store generated class labels for test transactions, change ttbase into address of file that include test transactions, change rbase into address of file that includes all association rules; (2) save, close the file; (3) in a terminal, nativate to the folder of this file and type "select_rule.py", then hit Enter to run the code.
		5.7.6 accuracy.py: containing code for calculating classification accuracy by running 5.7.5. To run the code, (1) open the file, change tlbase into address of file containing classified test labels from 5.7.5, change blbase into address lf file containing binary class labels for test dataset generated by running 5.7.1; (2) save, close the file; (3) in a terminal, nativate to the folder of this file and type "accuracy.py", then hit Enter to run the code.
	5.8 "algorithm2" folder: contains code to use above method for classification in algorithm2.
		5.8.1 partition_into_clusters.py: containing code to partition the binary dataset into clusters, and for each clusters, the dataset is further partitioned into training dataset and test dataset. To run the code, (1) open the file, change clusterinto into address of file of either 2.5 or 2.6 (depends on which clustering you want to work with), change tan into address of file 2.4, change tran into address of file 2.3, change allvector into address of file 2.1, change alllabel into address of file 2.2, and change folder into address of folder where you want to store the binary test dataset and training dataset; (3) save, close the file; (4) in a terminal, nativate to the folder of this file and type "partition_into_clusters.py", then hit Enter to run the code.  
		5.8.2 create_transactions.py: similar to 5.7.2
		5.8.3 prune_cluster.py: similar to 5.7.3
		5.8.4 leftover_cluster.py: similar to 5.7.4
		5.8.5 select_rules.py: similar to 5.7.5
		5.8.6 accuracy2.py: similar to 5.7.6
		